Before toposort:
No.0->myAdd3
No.1->myAdd2
After toposort:
No.0->myAdd2
No.1->myAdd3
[08/13/2022-15:20:06] [TRT] [I] [MemUsageChange] Init CUDA: CPU +196, GPU +0, now: CPU 215, GPU 404 (MiB)
[08/13/2022-15:20:06] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +6, GPU +2, now: CPU 240, GPU 406 (MiB)
[08/13/2022-15:20:06] [TRT] [I] ----------------------------------------------------------------
[08/13/2022-15:20:06] [TRT] [I] Input filename:   /work/gitlab/tensorrt-cookbook-in-chinese/08-Tool/OnnxGraphSurgeon/model-06-04.onnx
[08/13/2022-15:20:06] [TRT] [I] ONNX IR version:  0.0.8
[08/13/2022-15:20:06] [TRT] [I] Opset version:    11
[08/13/2022-15:20:06] [TRT] [I] Producer name:    
[08/13/2022-15:20:06] [TRT] [I] Producer version: 
[08/13/2022-15:20:06] [TRT] [I] Domain:           
[08/13/2022-15:20:06] [TRT] [I] Model version:    0
[08/13/2022-15:20:06] [TRT] [I] Doc string:       
[08/13/2022-15:20:06] [TRT] [I] ----------------------------------------------------------------
[08/13/2022-15:20:07] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +255, GPU +106, now: CPU 495, GPU 512 (MiB)
[08/13/2022-15:20:07] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +114, GPU +46, now: CPU 609, GPU 558 (MiB)
[08/13/2022-15:20:07] [TRT] [I] Global timing cache in use. Profiling results in this builder pass will be stored.
[08/13/2022-15:20:07] [TRT] [I] Detected 1 inputs and 1 output network tensors.
[08/13/2022-15:20:07] [TRT] [I] Total Host Persistent Memory: 0
[08/13/2022-15:20:07] [TRT] [I] Total Device Persistent Memory: 0
[08/13/2022-15:20:07] [TRT] [I] Total Scratch Memory: 0
[08/13/2022-15:20:07] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 4 MiB
[08/13/2022-15:20:07] [TRT] [I] Total Activation Memory: 0
[08/13/2022-15:20:07] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +4, now: CPU 0, GPU 4 (MiB)
[08/13/2022-15:20:07] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
[08/13/2022-15:20:07] [TRT] [W] The getMaxBatchSize() function should not be used with an engine built from a network created with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag. This function will always return 1.
[08/13/2022-15:20:07] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 608, GPU 540 (MiB)
[08/13/2022-15:20:07] [TRT] [I] Loaded engine size: 0 MiB
[08/13/2022-15:20:07] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[08/13/2022-15:20:07] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[V] Loaded Module: polygraphy.util    | Path: ['/opt/conda/lib/python3.8/site-packages/polygraphy/util']
[V] Model: model-06-04.onnx
[V] Loaded Module: polygraphy         | Version: 0.38.0 | Path: ['/opt/conda/lib/python3.8/site-packages/polygraphy']
[V] Loaded extension modules: []
[V] Loaded Module: tensorrt           | Version: 8.4.1.5 | Path: ['/opt/conda/lib/python3.8/site-packages/tensorrt']
[I] Will generate inference input data according to provided TensorMetadata: {tensor0 [shape=(4, 3, 64, 64)]}
[I] onnxrt-runner-N0-08/13/22-15:20:05  | Activating and starting inference
[V] Loaded Module: onnxruntime        | Version: 1.12.0 | Path: ['/opt/conda/lib/python3.8/site-packages/onnxruntime']
[I] Creating ONNX-Runtime Inference Session with providers: ['CPUExecutionProvider']
[V] Loaded Module: numpy              | Version: 1.22.4 | Path: ['/opt/conda/lib/python3.8/site-packages/numpy']
[V] Loading inputs from data loader
[V] Generating data using numpy seed: 1
[V] Input tensor: tensor0 | Generating input data in range: [0.0, 1.0]
[I] onnxrt-runner-N0-08/13/22-15:20:05 
    ---- Inference Input(s) ----
    {tensor0 [dtype=float32, shape=(4, 3, 64, 64)]}
[V] Runner input metadata is: {tensor0 [dtype=float32, shape=('B', 3, 64, 64)]}
[I] onnxrt-runner-N0-08/13/22-15:20:05 
    ---- Inference Output(s) ----
    {tensor2 [dtype=float32, shape=(4, 3, 64, 64)]}
[I] onnxrt-runner-N0-08/13/22-15:20:05  | Completed 1 iteration(s) in 0.2449 ms | Average inference time: 0.2449 ms.
[I] trt-runner-N0-08/13/22-15:20:05     | Activating and starting inference
[V]     Setting TensorRT Optimization Profiles
[V]     Input tensor: tensor0 (dtype=DataType.FLOAT, shape=(-1, 3, 64, 64)) | Setting input tensor shapes to: (min=[1, 3, 64, 64], opt=[4, 3, 64, 64], max=[16, 3, 64, 64])
[I]     Configuring with profiles: [Profile().add('tensor0', min=[1, 3, 64, 64], opt=[4, 3, 64, 64], max=[16, 3, 64, 64])]
[I] Building engine with configuration:
    Workspace            | 1000000000 bytes (953.67 MiB)
    Precision            | TF32: False, FP16: False, INT8: False, Obey Precision Constraints: False, Strict Types: False
    Tactic Sources       | ['CUBLAS', 'CUBLAS_LT', 'CUDNN', 'EDGE_MASK_CONVOLUTIONS']
    Safety Restricted    | False
    Profiles             | 1 profile(s)
[I] Finished engine building in 0.323 seconds
[V] Found candidate CUDA libraries: ['/usr/local/cuda/lib64/libcudart.so.11.7.99', '/usr/local/cuda/lib64/libcudart.so.11.0', '/usr/local/cuda/lib64/libcudart.so']
[I] trt-runner-N0-08/13/22-15:20:05    
    ---- Inference Input(s) ----
    {tensor0 [dtype=float32, shape=(4, 3, 64, 64)]}
[V] Runner input metadata is: {tensor0 [dtype=float32, shape=(-1, 3, 64, 64)]}
[V] Setting binding: tensor0 (index: 0) to shape: (4, 3, 64, 64)
[I] trt-runner-N0-08/13/22-15:20:05    
    ---- Inference Output(s) ----
    {tensor2 [dtype=float32, shape=(4, 3, 64, 64)]}
[I] trt-runner-N0-08/13/22-15:20:05     | Completed 1 iteration(s) in 0.3722 ms | Average inference time: 0.3722 ms.
[V] Successfully ran: ['onnxrt-runner-N0-08/13/22-15:20:05', 'trt-runner-N0-08/13/22-15:20:05']
[I] Accuracy Comparison | onnxrt-runner-N0-08/13/22-15:20:05 vs. trt-runner-N0-08/13/22-15:20:05
[I]     Comparing Output: 'tensor2' (dtype=float32, shape=(4, 3, 64, 64)) with 'tensor2' (dtype=float32, shape=(4, 3, 64, 64))
[I]     Tolerance: [abs=0.001, rel=0.001] | Checking elemwise error
[I]         onnxrt-runner-N0-08/13/22-15:20:05: tensor2 | Stats: mean=4.4995, std-dev=0.2893, var=0.083692, median=4.502, min=4 at (3, 2, 35, 12), max=5 at (3, 0, 30, 21), avg-magnitude=4.4995
[V]             ---- Histogram ----
                Bin Range  |  Num Elems | Visualization
                (4  , 4.1) |       4986 | #######################################
                (4.1, 4.2) |       4912 | #######################################
                (4.2, 4.3) |       4978 | #######################################
                (4.3, 4.4) |       4840 | ######################################
                (4.4, 4.5) |       4785 | ######################################
                (4.5, 4.6) |       5011 | ########################################
                (4.6, 4.7) |       4908 | #######################################
                (4.7, 4.8) |       4915 | #######################################
                (4.8, 4.9) |       4899 | #######################################
                (4.9, 5  ) |       4918 | #######################################
[I]         trt-runner-N0-08/13/22-15:20:05: tensor2 | Stats: mean=4.4995, std-dev=0.2893, var=0.083692, median=4.502, min=4 at (3, 2, 35, 12), max=5 at (3, 0, 30, 21), avg-magnitude=4.4995
[V]             ---- Histogram ----
                Bin Range  |  Num Elems | Visualization
                (4  , 4.1) |       4986 | #######################################
                (4.1, 4.2) |       4912 | #######################################
                (4.2, 4.3) |       4978 | #######################################
                (4.3, 4.4) |       4840 | ######################################
                (4.4, 4.5) |       4785 | ######################################
                (4.5, 4.6) |       5011 | ########################################
                (4.6, 4.7) |       4908 | #######################################
                (4.7, 4.8) |       4915 | #######################################
                (4.8, 4.9) |       4899 | #######################################
                (4.9, 5  ) |       4918 | #######################################
[I]         Error Metrics: tensor2
[I]             Minimum Required Tolerance: elemwise error | [abs=4.7684e-07] OR [rel=1.1921e-07] (requirements may be lower if both abs/rel tolerances are set)
[I]             Absolute Difference | Stats: mean=7.9677e-08, std-dev=1.7789e-07, var=3.1644e-14, median=0, min=0 at (0, 0, 0, 0), max=4.7684e-07 at (0, 0, 0, 3), avg-magnitude=7.9677e-08
[V]                 ---- Histogram ----
                    Bin Range            |  Num Elems | Visualization
                    (0       , 4.77e-08) |      40939 | ########################################
                    (4.77e-08, 9.54e-08) |          0 | 
                    (9.54e-08, 1.43e-07) |          0 | 
                    (1.43e-07, 1.91e-07) |          0 | 
                    (1.91e-07, 2.38e-07) |          0 | 
                    (2.38e-07, 2.86e-07) |          0 | 
                    (2.86e-07, 3.34e-07) |          0 | 
                    (3.34e-07, 3.81e-07) |          0 | 
                    (3.81e-07, 4.29e-07) |          0 | 
                    (4.29e-07, 4.77e-07) |       8213 | ########
[I]             Relative Difference | Stats: mean=1.8076e-08, std-dev=4.0456e-08, var=1.6367e-15, median=0, min=0 at (0, 0, 0, 0), max=1.1921e-07 at (3, 2, 50, 63), avg-magnitude=1.8076e-08
[V]                 ---- Histogram ----
                    Bin Range            |  Num Elems | Visualization
                    (0       , 1.19e-08) |      40939 | ########################################
                    (1.19e-08, 2.38e-08) |          0 | 
                    (2.38e-08, 3.58e-08) |          0 | 
                    (3.58e-08, 4.77e-08) |          0 | 
                    (4.77e-08, 5.96e-08) |          0 | 
                    (5.96e-08, 7.15e-08) |          0 | 
                    (7.15e-08, 8.34e-08) |          0 | 
                    (8.34e-08, 9.54e-08) |          0 | 
                    (9.54e-08, 1.07e-07) |       3547 | ###
                    (1.07e-07, 1.19e-07) |       4666 | ####
[I]         PASSED | Difference is within tolerance (rel=0.001, abs=0.001)
[I]     PASSED | All outputs matched | Outputs: ['tensor2']
[I] PASSED | Command: /opt/conda/bin/polygraphy run model-06-04.onnx --onnxrt --trt --pool-limit workspace:1000000000 --atol 1e-3 --rtol 1e-3 --verbose --trt-min-shapes tensor0:[1,3,64,64] --trt-opt-shapes tensor0:[4,3,64,64] --trt-max-shapes tensor0:[16,3,64,64] --input-shapes tensor0:[4,3,64,64]
