#
# Copyright (c) 2021-2023, NVIDIA CORPORATION. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

#-------------------------------------------------------------------------------
print("Succeeded building network!")
del engineString, engine, context
from NetworkInspector import inspectNetwork
from NetworkRebuilder import rebuildNetwork

if "profile" not in locals().keys():
    inspectNetwork(builder, config, network)
else:
    inspectNetwork(builder, config, network, [profile])  # seems ugly if we can not get optimization profile from BuilderConfig

engineString = rebuildNetwork(logger)

engine = trt.Runtime(logger).deserialize_cuda_engine(engineString)
context = engine.create_execution_context()
#context.set_binding_shape(0, data.shape)
#context.set_shape_input(0, data)
nInput = np.sum([engine.binding_is_input(i) for i in range(engine.num_bindings)])
nOutput = engine.num_bindings - nInput
for i in range(nInput):
    print("Bind[%2d]:i[%2d]->" % (i, i), engine.get_binding_dtype(i), engine.get_binding_shape(i), context.get_binding_shape(i), engine.get_binding_name(i))
for i in range(nInput, nInput + nOutput):
    print("Bind[%2d]:o[%2d]->" % (i, i - nInput), engine.get_binding_dtype(i), engine.get_binding_shape(i), context.get_binding_shape(i), engine.get_binding_name(i))

bufferH2 = []
for i in range(nInput):
    bufferH2.append(bufferH[i])
for i in range(nOutput):
    bufferH2.append(np.empty(context.get_binding_shape(nInput + i), dtype=trt.nptype(engine.get_binding_dtype(nInput + i))))
bufferD2 = []
for i in range(engine.num_bindings):
    bufferD2.append(cudart.cudaMalloc(bufferH2[i].nbytes)[1])

for i in range(nInput):
    cudart.cudaMemcpy(bufferD2[i], np.ascontiguousarray(bufferH2[i].reshape(-1)).ctypes.data, bufferH2[i].nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice)
context.execute_v2(bufferD2)
for i in range(nOutput):
    cudart.cudaMemcpy(bufferH2[nInput + i].ctypes.data, bufferD2[nInput + i], bufferH2[nInput + i].nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost)

#for i in range(nInput):
#    print("Input %d:" % i, bufferH2[i].shape, "\n", bufferH2[i])
for i in range(nOutput):
    print("Output %d:" % i, bufferH2[nInput + i].shape, "\n", bufferH2[nInput + i])

for buffer in bufferD2:
    cudart.cudaFree(buffer)

def check(a, b, weak=False, checkEpsilon=1e-5):
    if weak:
        res = np.all(np.abs(a - b) < checkEpsilon)
    else:
        res = np.all(a == b)
    diff0 = np.max(np.abs(a - b))
    diff1 = np.max(np.abs(a - b) / (np.abs(b) + checkEpsilon))
    print("check:%s, absDiff=%f, relDiff=%f" % (res, diff0, diff1))

print("\nCHECK")
for i in range(nInput, nInput + nOutput):
    check(bufferH[i], bufferH2[i])
